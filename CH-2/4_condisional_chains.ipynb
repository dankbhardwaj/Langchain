{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78287e0f",
   "metadata": {},
   "source": [
    "# *CONDINIONAL CHAINS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db083669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kubernetes is like a big, smart playground for computer programs called containers to live and work together harmoniously. Imagine you have different Lego sets that need to be built into one giant structure; each set has its own instructions (code) but they all come together as part of the same project. Kubernetes helps manage these \"Legos\" by making sure everything is organized, running smoothly and efficiently without any crashes or mix-ups when you add more pieces over time. It's like having a super smart assistant who knows exactly how to keep your Lego creation stable while adding new parts!\n",
      "Here's an example of a basic Terraform configuration file that creates an Amazon Web Services (AWS) Elastic Compute Cloud (EC2) instance:\n",
      "\n",
      "```hcl\n",
      "provider \"aws\" {\n",
      "  region = \"us-east-1\" # or any other AWS region you prefer to use.\n",
      "}\n",
      "\n",
      "resource \"aws_instance\" \"example\" {\n",
      "  ami           = \"ami-0c98edb6f7d3feccdb52\" # This is an Amazon Linux AMI in us-east-1, replace it with the appropriate one for your region and OS.\n",
      "  instance_type = \"t2.micro\" # or any other EC2 instance type you prefer to use.\n",
      "\n",
      "  tags = {\n",
      "    Name = \"example-instance\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "This code will create a single AWS t2.micro EC2 instance with the name `example-instance` in the us-east-1 region using an Amazon Linux AMI (Adjust as needed). You can customize this example to suit your specific needs, such as adding additional tags or specifying different AMIs and instance types.\n",
      "\n",
      "To deploy this configuration:\n",
      "\n",
      "1. Save it into a file with `.tf` extension, for example `ec2_instance.tf`.\n",
      "2. Open the terminal/command prompt in the directory containing that file.\n",
      "3. Run these commands to initialize Terraform, review changes and apply them (make sure you have installed Terraform):\n",
      "\n",
      "```bash\n",
      "terraform init\n",
      "terraform validate\n",
      "terraform plan # Review before applying!\n",
      "terraform apply\n",
      "``` \n",
      "\n",
      "Remember always check the AWS pricing for any resources that your code is creating to avoid unexpected costs.\n",
      "The `CrashLoopBackOff` status indicates that a container within the Kubernetes Pod has repeatedly entered a state where it is unable to start. This typically occurs when there's an issue with either the application code, configuration settings, or dependencies required for running the app inside the Container. Here are some steps and considerations you can take to troubleshoot this error:\n",
      "\n",
      "1. Check logs of failed pod using `kubectl` command: \n",
      "```bash\n",
      "kubectl describe pod <pod-name> -n <namespace> | grep \"CrashLoopBackOff\"\n",
      "```\n",
      "This will provide detailed information about the issue, including any errors in application code or configuration settings. Look for patterns and try to identify what might be causing these issues. \n",
      "\n",
      "2. Check container logs: Use `kubectl` command again but this time check inside of a specific Container using `--pod <pod-name> --container <container-name>` option, then look at the output or errors in that particular container log stream with `-c`:\n",
      "```bash endpoints=$(kubectl get pods -o jsonpath='{.items[*].metadata.labels.\"<label_key>\"}[0].value}')  kubectl logs $(echo ${endpoints}) --previous | grep \"CrashLoopBackOff\" ```\n",
      "This will provide specific details about the container's issue and help you pinpoint where things are going wrong within your application code or configuration.\n",
      "\n",
      "3. Check resource requirements: Sometimes, a `CrashLoopBackOff` error can be caused by insufficient resources (CPU/memory) allocated to Pods in Kubernetes Cluster. You may need to increase the CPU and memory requests for that particular pod using `--resource-requests`: \n",
      "```bash kubectl edit pod <pod-name> -n <namespace>``` then update resource request values, save changes, and apply them with `kubectl` command again: ```kubectl set env --patch '{ \"value\": \"{ \\\"CPU_REQUEST\\\": \\\"100m\\\",\\\"MEMORY_REQUEST\\\": \\\"256Mi\\\",\" }\"' -n <namespace> pod/<pod-name>```\n",
      "This will allocate more resources to the Pod, which may help in resolving this issue. \n",
      "\n",
      "4. Check dependencies: If your application depends on external services or databases (e.g., PostgreSQL), ensure that these are accessible and running correctly before deploying it inside Kubernetes Cluster using `kubectl` command with `--dry-run=client`: ```kubectl create -f <deployment-file> --dry-run=client```\n",
      "If there's an issue accessing external services, you may need to update your application configuration or network settings. \n",
      "\n",
      "5. Check for environment issues: If the `CrashLoopBackOff` error persists despite fixing dependencies and resource requirements, it might be caused by environmental factors such as incorrect configurations in `.env` files, missing required libraries/modules, etc. Double-check these aspects of your application's configuration to ensure they are correct.\n",
      "\n",
      "6. Check for code issues: If the `CrashLoopBackOff` error persists despite fixing dependencies and resource requirements, it might be caused by environmental factors such as incorrect configurations in `.env` files or missing required libraries/modules. Double-check these aspects of your application's configuration to ensure they are correct.\n",
      "\n",
      "7. Check for Kubernetes issues: Sometimes the issue may not lie with the code but rather within how you have configured and deployed it on Kubernetes Cluster itself, such as incorrect resource requests or limits set in Pod specification files (YAML/JSON), misconfigured network policies, etc. Review your deployment configuration to ensure that everything is correct before redeploying:\n",
      "```bash kubectl apply -f <pod-yaml> --dry-run=client ``` \n",
      "This will help you identify any issues with the Pod specification file itself and make necessary changes if needed.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "llm = ChatOllama(model=\"phi3:latest\", temperature=0.3)\n",
    "explain_chain = (\n",
    "    PromptTemplate.from_template(\"Explain {input} simply.\")\n",
    "    | llm\n",
    ")\n",
    "\n",
    "code_chain = (\n",
    "    PromptTemplate.from_template(\"Generate Terraform code for {input}.\")\n",
    "    | llm\n",
    ")\n",
    "\n",
    "error_chain = (\n",
    "    PromptTemplate.from_template(\"Analyze this DevOps error: {input}\")\n",
    "    | llm\n",
    ")\n",
    "router = RunnableBranch(\n",
    "    (lambda x: \"error\" in x[\"input\"].lower(), error_chain),\n",
    "    (lambda x: \"generate\" in x[\"input\"].lower(), code_chain),\n",
    "    explain_chain  # default\n",
    ")\n",
    "print(router.invoke({\"input\": \"Explain Kubernetes\"}).content)\n",
    "\n",
    "print(router.invoke({\"input\": \"Generate Terraform for AWS EC2\"}).content)\n",
    "\n",
    "print(router.invoke({\"input\": \"ERROR CrashLoopBackOff in pod\"}).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e1ac126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ansible is a simple, open-source IT automation tool that helps in managing and orchestrating tasks on multiple systems from one central location using plain text language files called playbooks. It uses SSH for communication between the control node (the machine running ansible) and managed nodes (servers or devices). Playbooks are written with YAML, which is easy to read even by non-technical users. Ansible can automate repetitive tasks like software installation, system configuration management, backups, etc., without worrying about the underlying infrastructure'nereness'. It does not require any special agents on managed nodes and it scales well for large numbers of devices or servers.\n",
      "The provided text \"ERROR ImagePuLLBackOFF\" appears to be a misinterpretation or incorrect transcription of an actual issue encountered within the context of Kubernetes. However, I can infer that you might have meant something like this:\n",
      "\n",
      "```yaml\n",
      "Error occurred during task execution in Kubernetes: Backoff Limit Exceeded for ImagePullBackOff status\n",
      "```\n",
      "\n",
      "This error typically indicates a problem with pulling an image from a container registry to create or update pods within your cluster. Here's how you might analyze and troubleshoot this issue step-bythought process, assuming the above interpretation is correct:\n",
      "\n",
      "1. **Understand Kubernetes Image Pulling**: In Kubernetes (K8s), images are stored in a registry like Docker Hub or Google Container Registry/Cloud Storage. When you create pods with these images as dependencies, they need to be pulled from this external source before the pod can start running.\n",
      "\n",
      "2. **Check Image Pulling Status**: Use `kubectl` command-line tool to get detailed information about your failed deployment or job that caused an image pull error by executing a query like so (replace `<pod_name>` with actual name):\n",
      "    ```shell\n",
      "    kubectl describe pod <pod_name> -n [namespace] \n",
      "    ```\n",
      "   Look for the `Status` section, where you should find information about any issues that occurred during image pulling. If it says \"ImagePullBackOff,\" this means Kubernetes was unable to pull an appropriate container from a registry and hence couldn't start your pod or job as planned. \n",
      "    ```yaml\n",
      "   Status:      \n",
      "      Conditions:\n",
      "        LastProbeTime:         Fri, 06 Jan 2023 14:58:27 GMT\n",
      "        LastTransitionTime:   Thu, 05 Jan 2023 19:00:00 UTC    (current time)\n",
      "        Ready:                 False\n",
      "        PodScheduled:          True\n",
      "      Phase:           Pending\n",
      "      StartTime:      Fri, 06 Jan 2023 14:58:27 GMT\n",
      "```\n",
      "   In this example output, the pod is in a \"Pending\" phase and has not yet started running because it's waiting for an image to be pulled. The `LastProbeTime` indicates when Kubernetes last attempted to pull that image before failing with ImagePullBackOff status. \n",
      "    ```shell\n",
      "   Events:                        <none> (most recent call last)\n",
      "    Warning Name:                ErrImagePull\n",
      "    Type:                        Error\n",
      "    Reason:                      Failed\n",
      "    Message:                     Failed to pull image \"image_name:tag\": rpc error: code = Unknown desc = context deadline exceeded \n",
      "    ```\n",
      "   Here, the `Message` field provides more details about why Kubernetes failed in pulling an appropriate container from a registry. In this case, it says that there was some issue with reaching out to your image repository (like network issues or incorrect credentials). This is where you need to troubleshoot further based on these specifics of failure messages provided by the system when attempting to pull images for pod creation/update operations in Kubernetes.\n",
      "    ```shell\n",
      "   BackOff:           True\n",
      "   Reason:            ImagePullBackOff\n",
      "   ```\n",
      "3. **Troubleshooting**: Once you've identified that an image is causing issues, here are some common troubleshooting steps to resolve the issue: \n",
      "     - Check your internet connectivity and ensure it can reach Docker Hub or other container registries where images reside (if applicable). If not using a public registry like DockerHub, make sure you have access permissions for private repositories. You may need to configure `kubectl` with the correct credentials if necessary:\n",
      "        ```shell\n",
      "         kubectl create secret docker-env --from-file GCR_JSON=$(gcloud auth application-default login) \n",
      "        ```\n",
      "     - Verify that your image is available in Docker Hub or other registries. You can do this by running `docker images` command locally and checking if the desired image exists there with a matching tag (if applicable). If not, you might need to push it first:\n",
      "         ```shell\n",
      "          docker push <image_name>:<tag> \n",
      "         ```\n",
      "     - Check your Kubernetes cluster's configuration for any issues related to pulling images. This includes checking the `kubelet` and other components that interact with container registries, as well as ensuring you have appropriate permissions (if using a private registry). You might also want to check if there are network policies or firewall settings in place which may be blocking access from your Kubernetes nodes/workers.\n",
      "     - If the issue persists after trying these steps above and checking that images exist, try pulling them again with `kubectl` command: \n",
      "        ```shell\n",
      "         kubectl run test-pod --image=<image_name>:<tag> --dry-run=client -n <namespace> --output=yaml | kubectl create -f -\n",
      "        ```\n",
      "     If you're still unable to pull the image, it might be worthwhile reaching out for help on community platforms like Stack Overflow or Kubernetes Slack channels. Provide as much detail about your environment and error messages so that others can provide more targeted advice based on their experience with similar issues in different contexts.\n",
      "     - If you're using a CI/CD pipeline, make sure the image is being built successfully before attempting to deploy it into Kubernetes (if applicable). This might involve checking build logs or running builds locally and pushing images manually as needed until they work correctly within your environment. \n",
      "    ```shell\n",
      "         kubectl create -f <deployment_file>.yaml --record=false\n",
      "        ```\n",
      "     If you're using Helm, make sure the values file contains correct image repository details (if applicable). You can also try to force a new deployment by deleting and recreating your resources: \n",
      "    ```shell\n",
      "         kubectl delete pods -n <namespace> --selector=app=<pod_name> && kubectl apply -f <deployment.yaml>\n",
      "        ```\n",
      "4. **Monitoring**: Once the issue is resolved, monitor your cluster's performance to ensure that it continues working as expected and no similar issues arise in future deployments or updates. You can use tools like Prometheus for monitoring Kubernetes resources if necessary (if applicable). \n",
      "    ```shell0-13T20:58:27Z] EOF\n",
      "```\n",
      "Here is a basic example of how to create an Azure Virtual Machine using Terraform:\n",
      "\n",
      "First, you will need to install the required providers by adding these lines at the top of your main.tf file or in separate provider.tf files if needed:\n",
      "\n",
      "```hcl\n",
      "terraform {\n",
      "  required_providers {\n",
      "    azurerm = {\n",
      "      source  = \"hashicorp/azurerm\"\n",
      "      version = \"=2.0.0\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "provider \"azurerm\" {\n",
      "  features {}\n",
      "}\n",
      "```\n",
      "\n",
      "Next, define your resource for the Azure Virtual Machine in a separate file (e.g., main.tf):\n",
      "\n",
      "```hcl\n",
      "resource \"azurerm_resource_group\" \"example\" {\n",
      "  name     = \"example-resources\"\n",
      "  location = \"East US\"\n",
      "}\n",
      "\n",
      "resource \"azurerm_virtual_network\" \"example\" {\n",
      "  name      = \"example-Vnet\"\n",
      "  address_space [](\"10.0.0.0/16\")\n",
      "  resource_group_name = azurerm_resource_group.example.name\n",
      "}\n",
      "\n",
      "resource \"azurerm_subnet\" \"example\" {\n",
      "  name       = \"example-Subnet\"\n",
      "  address_prefix [](\"10.0.1.0/24\")\n",
      "  virtual_network_name = azurerm_virtual_network.example.name\n",
      "  resource_group_name = azurerm_resource_group.example.name\n",
      "}\n",
      "\n",
      "resource \"azurerm_network_interface\" \"example\" {\n",
      "  name     = \"example-NIC\"\n",
      "  location = azurerm_resource_group.example.location\n",
      "  resource_group_name = azurerm_resource_group.example.name\n",
      "\n",
      "  ip_configuration {\n",
      "    name         = \"example-IpConfig\"\n",
      "    subnet_id    = azurerm_subnet.example.id\n",
      "    private_ip_allocation = \"dynamic\"\n",
      "  }\n",
      "}\n",
      "\n",
      "resource \"azurerm_linux_virtual_machine\" \"example\" {\n",
      "  name                = \"example-VM\"\n",
      "  resource_group_name = azurerm_resource_group.example.name\n",
      "  location            = azurerm_resource_group.example.location\n",
      "  size                = \"Standard_B1s\"\n",
      "  network_interface   = [for nic in azurerm_network_interface.example.id: nic]\n",
      "\n",
      "  os_disk {\n",
      "    caching              = \"ReadWrite\"\n",
      "    storage_account_type = \"StandardSSD_LRS\"\n",
      "\n",
      "    initialize_data_storage = false\n",
      "    diagnostics_storage_account_id = azurerm_resource_group.example.default_diagnostics_storage_account_id\n",
      "  }\n",
      "\n",
      "  source_image_reference {\n",
      "    publisher = \"Canonical\"\n",
      "    offer     = \"UbuntuServer\"\n",
      "    sku       = \"16.04-LTS\"\n",
      "    version   = \"latest\"\n",
      "  }\n",
      "\n",
      "  admin_username = \"adminuser\"\n",
      "  ssh_authorized_keys = [\n",
      "      \"# Ubuntu - OpenSSH\\n${var.ssh_public_key}\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Make sure to replace `example-resources`, `East US`, and other placeholder values with your desired names, locations, etc. You can also customize the VM size (e.g., \"Standard_B1s\") as per your requirements.\n",
      "\n",
      "Finally, set up a variable file for SSH public key authentication by creating a variables.tf file:\n",
      "\n",
      "```hcl\n",
      "variable \"ssh_public_key\" {\n",
      "  type        = string\n",
      "  description = \"SSH Public Key to be used with the VM.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Initialize and apply your Terraform configuration using these commands in PowerShell or Azure CLI (make sure you have already logged into Azure):\n",
      "\n",
      "```powershell\n",
      "terraform init\n",
      "terraform plan -out tfplan.tfplan\n",
      "az storage account create --name terraform-state-account --location \"East US\" --sku Standard_LRS --encryption-key-type `\n",
      "    KeyVault`Key`softDelete=false --resource-group example-resources\n",
      "```\n",
      "\n",
      "Now, apply your Terraform configuration:\n",
      "\n",
      "```powershell\n",
      "terraform apply tfplan.tfplan\n",
      "```\n",
      "\n",
      "This will create an Azure Virtual Machine with the specified settings and a public IP address for access via SSH using the provided key pair.\n"
     ]
    }
   ],
   "source": [
    "def explain_tool(input_text):\n",
    "    return llm.invoke(f\"Explain {input_text} simply.\").content\n",
    "\n",
    "def error_tool(input_text):\n",
    "    return llm.invoke(f\"Analyze this DevOps error: {input_text}\").content\n",
    "\n",
    "def generate_tool(input_text):\n",
    "    return llm.invoke(f\"Generate Terraform code for {input_text}\").content\n",
    "def decide_tool(user_input):\n",
    "    decision = llm.invoke(f\"\"\"\n",
    "    Decide which category this belongs to:\n",
    "    1. explain\n",
    "    2. error\n",
    "    3. generate\n",
    "\n",
    "    Input: {user_input}\n",
    "    \n",
    "    Return only one word.\n",
    "    \"\"\").content.lower()\n",
    "    \n",
    "    return decision.strip()\n",
    "def devops_agent(user_input):\n",
    "    decision = decide_tool(user_input)\n",
    "    \n",
    "    if \"error\" in decision:\n",
    "        return error_tool(user_input)\n",
    "    elif \"generate\" in decision:\n",
    "        return generate_tool(user_input)\n",
    "    else:\n",
    "        return explain_tool(user_input)\n",
    "print(devops_agent(\"Explain Ansible\"))\n",
    "print(devops_agent(\"ERROR ImagePuLLBackOFF IN Kubernetes\"))\n",
    "print(devops_agent(\"Generate Terraform for Azure VM\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
