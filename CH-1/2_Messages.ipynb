{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbf6de89",
   "metadata": {},
   "source": [
    "# *PROMTS*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "276c5b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(\n",
    "    model=\"phi3:latest\",\n",
    "    num_predict=60\n",
    ")\n",
    "\n",
    "print(llm.invoke(\"Say hello in one short sentence.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e76c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Simple Definition of Kubernetes (k8s):**  \n",
      "\n",
      "Kubernetes, often abbreviated as 'k8s,' is an open-source container orchestration system that automates the deployment, scaling, and operations management of application containers. It simplifies running applications in a microservices architecture across clusters of computers using various cloud providers or on-premise environments.\n",
      "\n",
      "\n",
      "**Real-world example:**  \n",
      "\n",
      "Imagine an online retail\n",
      "\n",
      "**Definition of Docker in simple terms:**\n",
      "\n",
      "Docker is like a special tool that helps build, test and run applications inside containersâ€”think of these as secure environments where apps live safely without interfering with each other on your computer or server. This makes sure everything runs smoothly no matter what system you're using. \n",
      "\n",
      "\n",
      "**Real-world example:**\n",
      "\n",
      "Imagine a chef needs to make the same dish for different customers, but they\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# Create model\n",
    "llm = OllamaLLM(\n",
    "    model=\"phi3:latest\",\n",
    "    num_predict=100\n",
    ")\n",
    "\n",
    "# Create template\n",
    "template = \"\"\"\n",
    "You are a senior DevOps engineer.\n",
    "\n",
    "Explain the following topic clearly:\n",
    "{topic}\n",
    "\n",
    "Give:\n",
    "1. Simple definition\n",
    "2. Real-world example\n",
    "3. Why it is important\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create chain\n",
    "chain = prompt | llm\n",
    "\n",
    "# Run\n",
    "response = chain.invoke({\"topic\": \"Kubernetes\"})\n",
    "\n",
    "print(response)\n",
    "print(chain.invoke({\"topic\": \"Docker\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd58f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Integration (CI) and Continuous Deployment (CD) pipelines, also known as CI/CD pipelines or just CD pipelines, help automate the process of integrating code changes from multiple contributors into a single software product frequently without human intervention. In simple terms: When developers write new features or fix bugs in their respective parts of an application's codebase and then push those updates to version control repositories like Git, CI/CD pipelines automatically\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"phi3:latest\",\n",
    "    num_predict=100\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a senior DevOps engineer.\"),\n",
    "    (\"human\", \"Explain {topic} in simple terms.\")\n",
    "])\n",
    "\n",
    "chain = chat_prompt | llm\n",
    "\n",
    "response = chain.invoke({\"topic\": \"Ci cd pipelines\"})\n",
    "\n",
    "print(response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
