{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b70b7b",
   "metadata": {},
   "source": [
    "# *Pydantic Structured Output* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0a6acc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Definition:\n",
      " Docker is an open-source platform designed to make it easier for developers to build, test and deploy applications by using containers.\n",
      "\n",
      "ðŸ”§ Real World Example:\n",
      " A web application that uses Docker can be containerized with all its dependencies bundled into a single image. This ensures consistency across different development and production environments as the same code runs identically in both settings without requiring any changes to it or installing additional software packages.\n",
      "\n",
      "ðŸš€ Importance:\n",
      " Docker is important because it simplifies application deployment, reduces compatibility issues between applications running on various systems due to containerization of dependencies, enables faster testing cycles with consistent development and production environments, and\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class DevOpsAnswer(BaseModel):\n",
    "    definition: str = Field(description=\"Simple explanation\")\n",
    "    real_world_example: str = Field(description=\"Practical example\")\n",
    "    importance: str = Field(description=\"Why it is important\")\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "# Create parser\n",
    "parser = PydanticOutputParser(pydantic_object=DevOpsAnswer)\n",
    "\n",
    "# Use lightweight model\n",
    "llm = ChatOllama(\n",
    "    model=\"phi3:latest\",\n",
    "    temperature=0.2,\n",
    "    num_predict=150\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a DevOps expert.\"),\n",
    "    (\"human\", \"\"\"\n",
    "Return ONLY valid JSON.\n",
    "\n",
    "Topic: {topic}\n",
    "\n",
    "Format:\n",
    "{{\n",
    "  \"definition\": \"...\",\n",
    "  \"real_world_example\": \"...\",\n",
    "  \"importance\": \"...\"\n",
    "}}\n",
    "\"\"\")\n",
    "])\n",
    "chain = prompt | llm | parser\n",
    "response = chain.invoke({\n",
    "    \"topic\": \"Docker\"\n",
    "})\n",
    "\n",
    "def pretty_print(answer):\n",
    "    print(\"\\nðŸ“˜ Definition:\\n\", answer.definition)\n",
    "    print(\"\\nðŸ”§ Real World Example:\\n\", answer.real_world_example)\n",
    "    print(\"\\nðŸš€ Importance:\\n\", answer.importance)\n",
    "\n",
    "pretty_print(response)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67cc590e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Kubernetes, often shortened to \"k8s,\" is like the stage manager for apps and services in tech land. Imagine you have lots of web applications that need careful attention from start till finish; they grow up (deployed), travel around your computer network (run across different machines) smoothly without any hiccups, get clean after their show ends (terminated or scaled down safely), and even understand when to take a break. Kubernetes is the backstage crew that helps manage all this efficiently with minimal human fuss required â€“ it automatically handles scaling up servers during popular times of day for your app traffic spikes; redirects you from one server in case another fails, ensuring there\\'d never be an empty seat or unused resource wastage. Plus, its clever scheduling means if any piece needs updating (rolling update), Kubernetes makes sure only a tiny part is taken offline while the rest continues to work just fine without breaking a sweat â€“ allowing quick updates and fixes directly from source code changes with no downtime! It\\'s like having an assistant who does all your heavy lifting behind-the-scenes so you can focus on creating amazing apps instead. Kubernetes uses its own language called YAML, which is just fancy text files that describe how exactly everything should run together - setting up databases connections or defining the user interface layout in plain English style! This way developers save time as they don\\'t need to write complex scripts everytime there\\'s an update; instead with a few simple commands typed into their computer terminal (command-line), k8s does all this work underneath silently while we sit back and relax watching our web apps do wonders across the world without interruptions!\\n' additional_kwargs={} response_metadata={'model': 'phi3:latest', 'created_at': '2026-02-17T14:20:39.3480853Z', 'done': True, 'done_reason': 'stop', 'total_duration': 33415425200, 'load_duration': 5606086100, 'prompt_eval_count': 29, 'prompt_eval_duration': 2454613900, 'eval_count': 363, 'eval_duration': 24441127800, 'logprobs': None, 'model_name': 'phi3:latest', 'model_provider': 'ollama'} id='lc_run--019c6bf8-fd97-7210-89d4-a5bd0b71ebb5-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 29, 'output_tokens': 363, 'total_tokens': 392}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "class InputSchema(TypedDict):\n",
    "    topic: str\n",
    "\n",
    "llm = ChatOllama(model=\"phi3:latest\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a DevOps expert.\"),\n",
    "    (\"human\", \"Explain {topic} simply.\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"topic\": \"Kubernetes\"})\n",
    "\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
