{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "527e0f3c",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# *DevOps Tool Calling Agent (Ollama + LangChain)*\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73e74a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: \n",
      "My Kubernetes pod shows CrashLoopBackOff error.\n",
      "Provide root cause, fix plan and monitoring strategy.\n",
      "\n",
      "Selected tools: ['analyze_error', 'generate_fix', 'monitoring_strategy']\n",
      "\n",
      "=========== FINAL OUTPUT ===========\n",
      "\n",
      "**Root Cause Analysis Report:**  \n",
      "\n",
      "The `CrashLoopBackOff` status indicates that the Kubernetes pod is repeatedly crashing because it cannot start successfully within a certain amount of time, typically due to issues with container runtime or application code/configuration problems. Common causes include misconfigured environment variables, resource constraints (like memory limits), incompatible software versions between dependencies, and flaky tests leading to unstable builds.\n",
      "\n",
      "**Fix Plan:**  \n",
      "1. Check the pod's logs using `kubectl logs <pod-name>` for immediate insights into what might be failing during startup.\n",
      "2. Validate that all environment variables are correctly set in your Pod specification and match those expected by your application, if any such expectations exist (e.g., database connection strings).\n",
      "3. Review resource requests and limits to ensure the pod has enough resources allocated; adjust them as necessary using `kubectl edit` or modifying `.spec.resources`.\n",
      "4. Update incompatible software versions within dependencies by checking your application's requirements against Kubernetes container images available on Docker Hub, Tiller (if Helm is used), and other repositories you might be utilizing for deployment.\n",
      "5. If tests are causing the issue due to flakiness or timeout errors, consider optimizing test suites with more robust testing frameworks like JUnit/TestNG if applicable, or adjusting Kubernetes' `restartPolicy` from 'Always'/'OnFailure' to a higher value that allows for retries.\n",
      "6. If the application code is suspected as an issue (e.g., unhandled exceptions), review recent changes and roll back if necessary while investigating further in development environments outside of Kubernetes, or fix identified issues before redeploying.\n",
      "7. Ensure proper health checks are configured for your pod to allow `kubectl` to understand when the application is ready; this can be done by setting appropriate liveness and readiness probes within your Pod specification.\n",
      "8. If all else fails, consider simplifying or isolating components of your deployment in separate containers/pods as a troubleshooting step before reintegrating into full-scale production deployments.\n",
      "\n",
      "**Monitoring Strategy:**  \n",
      "1. Implement `kubectl` command to continuously monitor the pod's status and logs for any recurring issues or patterns that emerge post-fix application, using a script if necessary (`while true; do kubectl get pod <pod-name> --output=json | jq '.status.conditions'; sleep 60; done`).\n",
      "2. Set up alerts with tools like Prometheus and Alertmanager to notify the team of any `CrashLoopBackOff` occurrences or other anomalies detected in your Kubernetes environment, using Helm charts for deployment if necessary (`helm install stable/prometheus-operator --set global.alertmanager.webhookConfigs=[{url: \"http://my-monitoring-service\"}]`).\n",
      "3. Use distributed tracing tools like Jaeger or Zipkin to trace requests through your application and identify potential bottlenecks, errors, or race conditions that could lead to crashes (deploy using Helm if necessary).\n",
      "4. Regularly review performance metrics for CPU/memory usage with Prometheus (`kubectl top pods <namespace> -n=<pod-namespace>`), ensuring the application is not being starved of resources, which can cause repeated failures to start up (deploy using Helm if necessary).\n",
      "5. Implement horizontal autoscaling policies for your deployment based on custom metrics or resource usage thresholds that trigger scaling actions when needed (`kubectl scale deploy/<deployment-name> --replicas=2` and setting this in a HorizontalPodAutoscaler with `kubectl apply -f`).\n",
      "6. Conduct periodic code reviews, static analysis, and integration testing to proactively identify potential issues before they affect production (use CI/CD tools like Jenkins or GitLabCI).\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ReAct Tool Agent (phi3 Compatible)\n",
    "# ==========================================\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Initialize LLM\n",
    "# -----------------------------\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"phi3:latest\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Define Tools\n",
    "# -----------------------------\n",
    "\n",
    "def analyze_error(error: str) -> str:\n",
    "    return f\"Root cause analysis for: {error}\"\n",
    "\n",
    "\n",
    "def generate_fix(issue: str) -> str:\n",
    "    return f\"Fix plan for: {issue}\"\n",
    "\n",
    "\n",
    "def monitoring_strategy(service: str) -> str:\n",
    "    return f\"Monitoring strategy for: {service}\"\n",
    "\n",
    "\n",
    "tools = {\n",
    "    \"analyze_error\": analyze_error,\n",
    "    \"generate_fix\": generate_fix,\n",
    "    \"monitoring_strategy\": monitoring_strategy\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Tool Selection Step\n",
    "# -----------------------------\n",
    "\n",
    "def select_tools(user_input: str):\n",
    "\n",
    "    decision_prompt = f\"\"\"\n",
    "You are a DevOps AI agent.\n",
    "\n",
    "Available tools:\n",
    "- analyze_error\n",
    "- generate_fix\n",
    "- monitoring_strategy\n",
    "\n",
    "Select required tools.\n",
    "Return only tool names separated by commas.\n",
    "Do not explain.\n",
    "\n",
    "User request:\n",
    "{user_input}\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke(decision_prompt).content.lower()\n",
    "\n",
    "    selected = []\n",
    "    for name in tools.keys():\n",
    "        if name in response:\n",
    "            selected.append(name)\n",
    "\n",
    "    return selected\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4️⃣ Agent Execution Loop\n",
    "# -----------------------------\n",
    "\n",
    "def run_agent(user_input: str):\n",
    "\n",
    "    print(\"\\nUser:\", user_input)\n",
    "\n",
    "    selected_tools = select_tools(user_input)\n",
    "\n",
    "    print(\"Selected tools:\", selected_tools)\n",
    "\n",
    "    observations = []\n",
    "\n",
    "    for tool_name in selected_tools:\n",
    "        result = tools[tool_name](user_input)\n",
    "        observations.append(f\"{tool_name} output: {result}\")\n",
    "\n",
    "    final_prompt = f\"\"\"\n",
    "User request:\n",
    "{user_input}\n",
    "\n",
    "Tool results:\n",
    "{chr(10).join(observations)}\n",
    "\n",
    "Provide structured DevOps response.\n",
    "\"\"\"\n",
    "\n",
    "    final_answer = llm.invoke(final_prompt).content\n",
    "\n",
    "    return final_answer\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5️⃣ Run Example\n",
    "# -----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    output = run_agent(\"\"\"\n",
    "My Kubernetes pod shows CrashLoopBackOff error.\n",
    "Provide root cause, fix plan and monitoring strategy.\n",
    "\"\"\")\n",
    "\n",
    "    print(\"\\n=========== FINAL OUTPUT ===========\\n\")\n",
    "    print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
